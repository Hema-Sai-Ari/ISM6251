{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e90866",
   "metadata": {},
   "source": [
    "# WE04-Universal Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba267ca",
   "metadata": {},
   "source": [
    "\n",
    "## Hema Sai Ari (U59528014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7ac3a",
   "metadata": {},
   "source": [
    "### 1.0 Import and install python libraries we require\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f634b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5d52a",
   "metadata": {},
   "source": [
    "### 2.0 Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16eb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UniversalBank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90c37e",
   "metadata": {},
   "source": [
    "### Overview of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dbfab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38720c9b",
   "metadata": {},
   "source": [
    "### Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892775a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#.info gives us the null character count and the data type of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab869d7",
   "metadata": {},
   "source": [
    " **We can observe that there are no categorical variables in the given data**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3aa6e",
   "metadata": {},
   "source": [
    "### Checking for missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70edfbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3aa0f",
   "metadata": {},
   "source": [
    "**Here we can clearlly obeserve that there are no missing values in the columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eba946",
   "metadata": {},
   "source": [
    "### Checking the count of unique data in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a85debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4698\n",
       "1     302\n",
       "Name: CD Account, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing the number of 0's and 1's in the target variable\n",
    "df['CD Account'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dab0c0",
   "metadata": {},
   "source": [
    "**We can clearly observe that the data have a huge imbalance in it which can effect the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be455ab1",
   "metadata": {},
   "source": [
    "## 3.0 Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a0332",
   "metadata": {},
   "source": [
    "We dont have any categorical variables and we dont have any missing values so we need not do any covertion into numeric or we need not impute values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd96e43",
   "metadata": {},
   "source": [
    "### Dropping unessasary columns\n",
    "\n",
    "Dropping unuseful data can help us to process the model quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f64bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ID, and Zip Code as predictors as they are not gonna effect the result \n",
    "df = df.drop(columns=['ID', 'ZIP Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf77ce",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037bcd4",
   "metadata": {},
   "source": [
    "Lets split the data into training data and the test data with the ratio of 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54713086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=1)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'CD Account'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e6136",
   "metadata": {},
   "source": [
    "### Now lets standardize the variables\n",
    "\n",
    "We standardize our variables to eliminate the differences in scale between the predictors/features. \n",
    "\n",
    "We will use the sklearn library's 'standard scaler' to accomplish this. The standard scaler function will standardize our variables. To achieve this, we will first need to train the scaler on the training data and then apply this trained scaler to standardize both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecfa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training and test sets\n",
    "X_train = scaler.transform(train_df[predictors]) \n",
    "y_train = train_df[target] \n",
    "\n",
    "X_test = scaler.transform(test_df[predictors])\n",
    "y_test = test_df[target] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2568de",
   "metadata": {},
   "source": [
    "## 4.0 Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedaa39",
   "metadata": {},
   "source": [
    "Lets create a data frame to store all the results of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afc5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae91863",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5bab7e",
   "metadata": {},
   "source": [
    "### 4.1.1 Logistic Regression using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412bfb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.6708245243128964\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 851, 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "910 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "280 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "340 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "290 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.66627907 0.66627907        nan 0.66627907 0.         0.66627907\n",
      " 0.66627907 0.66627907 0.66627907        nan        nan        nan\n",
      "        nan 0.31469345        nan 0.                nan        nan\n",
      " 0.66627907        nan 0.31469345 0.66627907        nan 0.37399577\n",
      " 0.66627907 0.66627907 0.         0.05940803        nan 0.\n",
      "        nan 0.67082452 0.66627907 0.66627907 0.37399577        nan\n",
      " 0.66627907 0.05940803 0.66627907 0.                nan 0.66627907\n",
      "        nan 0.05940803        nan        nan        nan 0.31469345\n",
      "        nan        nan        nan 0.         0.05940803        nan\n",
      "        nan 0.25095137        nan 0.37399577        nan        nan\n",
      " 0.05940803 0.66627907        nan        nan 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.25095137 0.66627907 0.\n",
      "        nan        nan 0.66627907 0.66627907 0.05940803 0.\n",
      "        nan 0.66627907 0.31469345        nan 0.66627907        nan\n",
      "        nan        nan 0.37399577 0.66627907 0.67082452 0.66627907\n",
      " 0.66627907 0.         0.66627907        nan        nan        nan\n",
      "        nan        nan 0.66627907 0.66627907        nan 0.66627907\n",
      "        nan 0.66627907 0.66627907 0.66627907 0.66627907 0.\n",
      " 0.67082452        nan        nan 0.66627907        nan        nan\n",
      "        nan 0.05940803 0.66627907 0.37399577 0.05940803        nan\n",
      "        nan        nan 0.66627907 0.66627907        nan        nan\n",
      " 0.67082452 0.66627907        nan 0.66627907 0.         0.05940803\n",
      " 0.31469345 0.66627907        nan 0.66627907        nan        nan\n",
      " 0.66627907        nan        nan 0.66627907 0.67082452 0.66627907\n",
      " 0.                nan        nan 0.66627907        nan 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907        nan 0.66627907 0.66627907\n",
      " 0.         0.66627907 0.66627907        nan 0.66627907 0.66627907\n",
      "        nan        nan 0.05940803        nan 0.66627907 0.66627907\n",
      " 0.67082452 0.66627907 0.25095137        nan        nan 0.66627907\n",
      " 0.66627907        nan        nan        nan 0.66627907 0.66627907\n",
      "        nan 0.         0.66627907 0.66627907 0.         0.66627907\n",
      "        nan 0.66627907        nan        nan 0.                nan\n",
      "        nan 0.66627907 0.67082452 0.66627907 0.                nan\n",
      " 0.66627907 0.66627907 0.66627907 0.         0.66627907 0.05940803\n",
      " 0.                nan        nan 0.66627907        nan        nan\n",
      " 0.05940803 0.66627907 0.66627907 0.66627907        nan        nan\n",
      " 0.66627907 0.67082452        nan 0.66627907 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907        nan 0.\n",
      "        nan 0.66627907 0.67082452        nan 0.         0.66627907\n",
      " 0.66627907        nan 0.25095137 0.05940803 0.05940803 0.\n",
      "        nan 0.66627907 0.66627907        nan 0.66627907        nan\n",
      " 0.66627907        nan 0.31469345 0.66627907 0.05940803 0.66627907\n",
      " 0.66627907 0.                nan 0.66627907 0.67082452 0.66627907\n",
      "        nan 0.         0.66627907 0.66627907 0.31469345        nan\n",
      " 0.         0.05940803 0.66627907        nan 0.66627907 0.37399577\n",
      " 0.66627907        nan 0.37399577 0.66627907 0.66627907 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.66627907 0.67082452 0.66627907\n",
      " 0.66627907        nan        nan        nan        nan 0.66627907\n",
      " 0.                nan 0.66627907        nan 0.         0.\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.31469345        nan\n",
      " 0.                nan 0.25095137        nan 0.66627907        nan\n",
      " 0.66627907        nan        nan        nan 0.66627907        nan\n",
      " 0.66627907 0.66627907        nan 0.                nan        nan\n",
      " 0.66627907 0.66627907        nan 0.05940803 0.66627907 0.66627907\n",
      " 0.31469345 0.         0.66627907        nan 0.66627907 0.25095137\n",
      " 0.66627907        nan        nan 0.66627907 0.66627907 0.66627907\n",
      "        nan 0.66627907 0.37399577 0.66627907 0.66627907 0.\n",
      " 0.37399577        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.05940803 0.66627907 0.66627907 0.67082452\n",
      " 0.         0.66627907        nan 0.31469345 0.66627907        nan\n",
      "        nan 0.66627907 0.66627907 0.37399577 0.66627907        nan\n",
      "        nan        nan 0.         0.66627907 0.66627907 0.31469345\n",
      " 0.66627907 0.66627907        nan 0.                nan 0.66627907\n",
      " 0.66627907 0.66627907        nan        nan 0.66627907        nan\n",
      " 0.         0.66627907        nan 0.66627907 0.66627907 0.66627907\n",
      " 0.05940803        nan 0.31469345 0.05940803 0.05940803        nan\n",
      " 0.05940803 0.66627907        nan        nan 0.67082452 0.66627907\n",
      " 0.37399577 0.25095137 0.66627907        nan 0.66627907 0.66627907\n",
      " 0.66627907        nan 0.31469345        nan 0.66627907 0.05940803\n",
      " 0.66627907        nan 0.66627907 0.66627907        nan        nan\n",
      " 0.66627907        nan        nan 0.66627907        nan 0.66627907\n",
      " 0.25095137 0.66627907        nan 0.         0.66627907 0.66627907\n",
      " 0.66627907 0.66627907        nan 0.66627907        nan 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.66627907 0.31469345\n",
      " 0.66627907        nan 0.67082452        nan 0.66627907 0.66627907\n",
      " 0.66627907 0.                nan        nan 0.66627907        nan\n",
      " 0.66627907        nan 0.31469345        nan        nan 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.37399577 0.66627907        nan\n",
      " 0.         0.66627907        nan 0.66627907        nan        nan\n",
      " 0.                nan 0.66627907 0.66627907 0.66627907 0.\n",
      "        nan        nan        nan 0.66627907        nan        nan\n",
      "        nan 0.37399577        nan        nan        nan 0.05940803\n",
      "        nan        nan 0.67082452 0.31469345        nan 0.66627907\n",
      " 0.66627907 0.66627907]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,10], # C is the regulization strength\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(500,1000)\n",
    "                  \n",
    "}\n",
    "\n",
    "lg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator =lg, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestlogestic = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cce49",
   "metadata": {},
   "source": [
    "**Now lets use these best parameters in the grid search so obatain best results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3693edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n",
      "The best recall score is 0.6708245243128964\n",
      "... with parameters: {'C': 0.05, 'max_iter': 551, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-0.05,min_regulization_strength+0.05), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-300,min_iter+300)\n",
    "}\n",
    "\n",
    "lgr =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = lgr, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestlgr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b6ce3",
   "metadata": {},
   "source": [
    "The obatined best recall score and the best parameters are for the trainning set. Now we will use those best paameters in the model to predict the test set results and then compare them with the acutal test set traget variabls and draw a confusion matrix. Using the confusion matrix we can get the scoring metrices values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77eacd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_lr={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf1ed57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall score from the Logestic Regression model using Random Search and Grid Search is :{0.6024096385542169}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The recall score from the Logestic Regression model using Random Search and Grid Search is :{Recall_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c4be3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b2de8",
   "metadata": {},
   "source": [
    "### 4.1.2 Modeling the data using individual logestic regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9d565a",
   "metadata": {},
   "source": [
    "#### 4.1.2.1 Fit and test a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ffd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none', max_iter=900)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78b3952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix_1 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_1[1][1]\n",
    "TN = c_matrix_1[0][0]\n",
    "FP = c_matrix_1[0][1]\n",
    "FN = c_matrix_1[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07585d6c",
   "metadata": {},
   "source": [
    "#### 4.1.2.2 Change to liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5713f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_liblin_model = LogisticRegression(solver='liblinear').fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "358bd5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_liblin_model.predict(X_test)\n",
    "c_matrix_2 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_2[1][1]\n",
    "TN = c_matrix_2[0][0]\n",
    "FP = c_matrix_2[0][1]\n",
    "FN = c_matrix_2[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"liblinear logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79295580",
   "metadata": {},
   "source": [
    "#### 4.1.2.3 L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c348fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "_ = log_reg_L2_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee84c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds_3 = log_reg_L2_model.predict(X_test)\n",
    "c_matrix_3 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_3[1][1]\n",
    "TN = c_matrix_3[0][0]\n",
    "FP = c_matrix_3[0][1]\n",
    "FN = c_matrix_3[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eeb360",
   "metadata": {},
   "source": [
    "#### 4.1.2.4 L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b581eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L1_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "_ = log_reg_L1_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecc49190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_L1_model.predict(X_test)\n",
    "c_matrix_4 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_4[1][1]\n",
    "TN = c_matrix_4[0][0]\n",
    "FP = c_matrix_4[0][1]\n",
    "FN = c_matrix_4[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L1 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03a5c1",
   "metadata": {},
   "source": [
    "#### 4.1.2.5 Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71671e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_elastic_model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5, max_iter=1000)\n",
    "_ = log_reg_elastic_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09c6ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                     Elestic logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_elastic_model.predict(X_test)\n",
    "c_matrix_5 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_5[1][1]\n",
    "TN = c_matrix_5[0][0]\n",
    "FP = c_matrix_5[0][1]\n",
    "FN = c_matrix_5[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Elestic logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8600e0",
   "metadata": {},
   "source": [
    "####  Summary for logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4057a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                     Elestic logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b822824",
   "metadata": {},
   "source": [
    "### 4.2 Model the data using the SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb8a41d",
   "metadata": {},
   "source": [
    "### 4.2.1 SVM using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "917d045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n",
      "The best recall score is 0.7214611872146118\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'coef0': 5, 'C': 40.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':np.arange(0.1,100,10),  #  regularization parameter.\n",
    "               'kernel':['linear', 'rbf','poly'],\n",
    "              'gamma':['scale','auto'],\n",
    "              'degree':np.arange(1,10), #degree is for the polynomial kernal\n",
    "              'coef0':np.arange(1,10) #coef0 is for the polynomial kernal\n",
    "                  \n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svc, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestsvc = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cea28c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "The best recall score is 0.7260273972602739\n",
      "... with parameters: {'C': 37.1, 'coef0': 7, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_kernel = rand_search.best_params_['kernel']\n",
    "best_gamma = rand_search.best_params_['gamma']\n",
    "min_regulization=rand_search.best_params_['C']\n",
    "best_degree = rand_search.best_params_['degree']\n",
    "best_coef0=rand_search.best_params_['coef0']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization-3,min_regulization+3), \n",
    "               'kernel':[best_kernel],\n",
    "              'gamma':[best_gamma],\n",
    "              'degree': np.arange(best_degree-1,best_degree+1),\n",
    "            'coef0': np.arange(best_coef0-3,best_coef0+3)\n",
    "}\n",
    "\n",
    "svm_grid =  SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac6b6f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9553333 Precision=0.5869565 Recall=0.6506024 F1=0.6171429\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_svm={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef1412cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall score from the SVM model using Random Search and Grid Search is {0.6506024096385542}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The recall score from the SVM model using Random Search and Grid Search is {Recall_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "700c0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm using Random & Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe4ac9",
   "metadata": {},
   "source": [
    "### 4.2.2 Modeling the Data using indivdual SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b167a",
   "metadata": {},
   "source": [
    "### 4.2.2.1 Fit a SVM classification model using linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a2c42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\")\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a822e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.978000   1.000000  0.602410   \n",
       "0                     default logistic  0.978000   1.000000  0.602410   \n",
       "0                   liblinear logistic  0.978000   1.000000  0.602410   \n",
       "0                          L2 logistic  0.978000   1.000000  0.602410   \n",
       "0                          L1 logistic  0.978000   1.000000  0.602410   \n",
       "0                     Elestic logistic  0.978000   1.000000  0.602410   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                           linear svm  0.978000   1.000000  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.617143  \n",
       "0  0.751880  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "c_matrix_6 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_6[1][1]\n",
    "TN = c_matrix_6[0][0]\n",
    "FP = c_matrix_6[0][1]\n",
    "FN = c_matrix_6[1][0]\n",
    "performance= pd.concat([performance, pd.DataFrame({'model':\"linear svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a45d3",
   "metadata": {},
   "source": [
    "### 4.2.2.2 Fit a SVM classification model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "814ad532",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7beead2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.978000   1.000000  0.602410   \n",
       "0                     default logistic  0.978000   1.000000  0.602410   \n",
       "0                   liblinear logistic  0.978000   1.000000  0.602410   \n",
       "0                          L2 logistic  0.978000   1.000000  0.602410   \n",
       "0                          L1 logistic  0.978000   1.000000  0.602410   \n",
       "0                     Elestic logistic  0.978000   1.000000  0.602410   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                           linear svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.617143  \n",
       "0  0.751880  \n",
       "0  0.724638  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "c_matrix_7 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_7[1][1]\n",
    "TN = c_matrix_7[0][0]\n",
    "FP = c_matrix_7[0][1]\n",
    "FN = c_matrix_7[1][0]\n",
    "performance= pd.concat([performance, pd.DataFrame({'model':\"rbf svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859ef55",
   "metadata": {},
   "source": [
    "### 4.2.2.3 Fit a SVM classification model using polynomial kernal¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c18b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52eb36bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.978000   1.000000  0.602410   \n",
       "0                     default logistic  0.978000   1.000000  0.602410   \n",
       "0                   liblinear logistic  0.978000   1.000000  0.602410   \n",
       "0                          L2 logistic  0.978000   1.000000  0.602410   \n",
       "0                          L1 logistic  0.978000   1.000000  0.602410   \n",
       "0                     Elestic logistic  0.978000   1.000000  0.602410   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                           linear svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "0                             poly svm  0.970000   0.806452  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.617143  \n",
       "0  0.751880  \n",
       "0  0.724638  \n",
       "0  0.689655  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "c_matrix_8 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_8[1][1]\n",
    "TN = c_matrix_8[0][0]\n",
    "FP = c_matrix_8[0][1]\n",
    "FN = c_matrix_8[1][0]\n",
    "performance= pd.concat([performance, pd.DataFrame({'model':\"poly svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360dd47",
   "metadata": {},
   "source": [
    "### Summary of the SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "355ea252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.978000   1.000000  0.602410   \n",
       "0                     default logistic  0.978000   1.000000  0.602410   \n",
       "0                   liblinear logistic  0.978000   1.000000  0.602410   \n",
       "0                          L2 logistic  0.978000   1.000000  0.602410   \n",
       "0                          L1 logistic  0.978000   1.000000  0.602410   \n",
       "0                     Elestic logistic  0.978000   1.000000  0.602410   \n",
       "0                           linear svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "0                             poly svm  0.970000   0.806452  0.602410   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "\n",
       "         F1  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.724638  \n",
       "0  0.689655  \n",
       "0  0.617143  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4221c4a",
   "metadata": {},
   "source": [
    "### 4.3 Model the data using the Decision Trees using RandomSearchCV combined with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c002220",
   "metadata": {},
   "source": [
    "Using the Random search to get the best parameters from the range which can be later used in the Grid search to get more refined results with less overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "749dfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.7076109936575052\n",
      "... with parameters: {'min_samples_split': 92, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 78, 'max_depth': 8, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.56162791 0.59830867 0.59830867 0.57547569 0.29682875 0.63890063\n",
      " 0.29682875 0.59830867 0.29682875 0.4846723  0.29682875 0.29682875\n",
      " 0.59830867 0.         0.63890063 0.29682875 0.59830867 0.63890063\n",
      " 0.59376321 0.14545455 0.36194503 0.59830867 0.59830867 0.59830867\n",
      " 0.56183932 0.36194503 0.59830867 0.62114165 0.56162791 0.59830867\n",
      " 0.63890063 0.59344609 0.59344609 0.12272727 0.29682875 0.14545455\n",
      " 0.59830867 0.29682875 0.67547569 0.48879493 0.59830867 0.59830867\n",
      " 0.         0.59830867 0.14545455 0.56162791 0.29682875 0.59830867\n",
      " 0.59830867 0.19545455 0.59830867 0.59830867 0.59830867 0.6845666\n",
      " 0.29682875 0.66649049 0.59830867 0.59830867 0.14545455 0.59830867\n",
      " 0.29682875 0.59830867 0.51638478 0.23773784 0.         0.\n",
      " 0.05       0.59830867 0.59830867 0.36194503 0.59830867 0.57526427\n",
      " 0.59830867 0.29682875 0.56162791 0.         0.59830867 0.63890063\n",
      " 0.59830867 0.29682875 0.59830867 0.55729387 0.59830867 0.56162791\n",
      " 0.59830867 0.59376321 0.         0.23773784 0.59830867 0.53890063\n",
      " 0.29682875 0.59830867 0.59830867 0.63890063 0.12272727 0.65264271\n",
      " 0.6435518  0.59830867 0.29682875 0.59830867 0.56183932 0.57526427\n",
      " 0.49788584 0.6256871  0.56162791 0.59830867 0.36194503 0.70295983\n",
      " 0.59830867 0.                nan 0.51638478 0.         0.67579281\n",
      " 0.59830867 0.66649049 0.56183932 0.56162791 0.29682875 0.59830867\n",
      " 0.70295983 0.69841438 0.59344609 0.         0.64799154 0.58002114\n",
      " 0.59830867 0.59830867 0.         0.63890063 0.14545455 0.29682875\n",
      " 0.59830867 0.14545455 0.56183932 0.59830867 0.51638478 0.31955603\n",
      " 0.63890063 0.36194503 0.59830867 0.05       0.29682875 0.59830867\n",
      " 0.         0.         0.36194503 0.29682875 0.59376321 0.59830867\n",
      " 0.59830867 0.48879493 0.4846723  0.64799154 0.59830867 0.652537\n",
      " 0.59830867 0.59830867 0.12272727 0.14545455 0.         0.29682875\n",
      " 0.55729387 0.60295983 0.23773784 0.59830867 0.64799154 0.\n",
      " 0.59830867 0.4846723  0.29682875 0.59830867 0.59344609 0.59830867\n",
      " 0.49788584 0.14545455 0.67082452 0.59830867 0.4602537  0.29682875\n",
      " 0.59830867 0.29682875 0.36194503 0.6845666  0.         0.56162791\n",
      " 0.56162791 0.56183932 0.59830867 0.59830867 0.59830867 0.59830867\n",
      " 0.59830867 0.53890063 0.05       0.59830867 0.4846723  0.55729387\n",
      " 0.59830867 0.63890063 0.59830867 0.29682875 0.59830867 0.59830867\n",
      " 0.63890063 0.64799154 0.59830867 0.59376321 0.59830867 0.59830867\n",
      " 0.55729387 0.59830867 0.59830867 0.59830867 0.59830867 0.56162791\n",
      " 0.59830867 0.6256871  0.59830867 0.59830867 0.70761099 0.57547569\n",
      " 0.29682875 0.14545455 0.         0.36194503 0.59830867 0.652537\n",
      " 0.66649049 0.58932347 0.63890063 0.         0.         0.29682875\n",
      " 0.29682875 0.         0.29682875 0.4846723  0.         0.\n",
      " 0.05       0.59830867 0.14545455 0.4846723  0.59830867 0.59830867\n",
      " 0.36194503 0.70295983 0.56162791 0.         0.59830867 0.59830867\n",
      " 0.29682875 0.12272727 0.59376321 0.57547569 0.70295983 0.56162791\n",
      " 0.59830867 0.48879493 0.29682875 0.14545455 0.14545455 0.12272727\n",
      " 0.29682875 0.59830867 0.59830867 0.66649049 0.59376321 0.29682875\n",
      " 0.59830867 0.23773784 0.14545455 0.29682875 0.59830867 0.59830867\n",
      " 0.29682875 0.59830867 0.57547569 0.59830867 0.59830867 0.63890063\n",
      " 0.57547569 0.59830867 0.36194503 0.63890063 0.29682875 0.14545455\n",
      " 0.         0.59830867 0.56183932 0.59830867 0.36194503 0.59830867\n",
      " 0.12272727 0.29682875 0.51638478 0.57547569 0.59830867 0.\n",
      " 0.59830867 0.51638478 0.56183932 0.23773784 0.4846723  0.59830867\n",
      " 0.65708245 0.55729387 0.54799154 0.51638478 0.14545455 0.29682875\n",
      " 0.59830867 0.         0.59830867 0.69841438 0.59830867 0.29682875\n",
      " 0.         0.54799154 0.63890063 0.59830867 0.63890063 0.59830867\n",
      " 0.54788584 0.59830867 0.54799154 0.59830867 0.         0.29682875\n",
      "        nan 0.59830867 0.29682875 0.29682875 0.29682875 0.49788584\n",
      " 0.6255814  0.57547569 0.51638478 0.58921776 0.59830867 0.64799154\n",
      " 0.29682875 0.59830867 0.29682875 0.29682875 0.59344609 0.54799154\n",
      " 0.59830867 0.64820296 0.59830867 0.50697674 0.63890063 0.\n",
      " 0.59830867 0.49788584 0.59830867 0.05       0.63890063 0.652537\n",
      " 0.         0.59830867 0.64799154 0.59830867 0.59830867 0.14545455\n",
      " 0.36194503 0.59830867 0.         0.63890063 0.59830867 0.59830867\n",
      " 0.14545455 0.59830867 0.56183932 0.05       0.         0.05\n",
      " 0.         0.59344609 0.56162791 0.66162791 0.59830867 0.59830867\n",
      " 0.59830867 0.59830867 0.59830867 0.59344609 0.68932347 0.\n",
      " 0.59830867 0.36194503 0.05       0.23773784 0.29682875 0.59830867\n",
      " 0.652537   0.59830867 0.36194503 0.56162791 0.29682875 0.29682875\n",
      " 0.         0.59830867 0.14545455 0.63890063 0.12272727 0.59344609\n",
      " 0.59830867 0.59830867 0.59830867 0.52061311 0.56162791 0.70295983\n",
      " 0.59830867 0.59830867 0.59830867 0.65718816 0.14545455 0.59830867\n",
      " 0.59830867 0.         0.         0.59830867 0.4846723  0.66649049\n",
      " 0.51638478 0.59830867 0.65295983 0.29682875 0.59830867 0.36194503\n",
      " 0.59830867 0.59830867 0.59830867 0.59830867 0.56162791 0.29682875\n",
      " 0.51638478 0.36194503 0.59830867 0.59830867 0.62103594 0.\n",
      " 0.59830867 0.59830867 0.59830867 0.29682875 0.59830867 0.59830867\n",
      " 0.29682875 0.69841438 0.56162791 0.12272727 0.59830867 0.59830867\n",
      " 0.6435518  0.59830867 0.59830867 0.50697674 0.59830867 0.12272727\n",
      " 0.54799154 0.59830867 0.59830867 0.59830867 0.59830867 0.12272727\n",
      " 0.12272727 0.29682875 0.59830867 0.23773784 0.59830867 0.29682875\n",
      " 0.59344609 0.59344609 0.59830867 0.29682875 0.59830867        nan\n",
      " 0.59830867 0.70295983 0.29682875 0.29682875 0.56162791 0.58921776\n",
      " 0.50697674 0.65718816 0.59830867 0.4846723  0.59830867 0.36194503\n",
      " 0.59830867 0.         0.54799154 0.14545455 0.59830867 0.57547569\n",
      " 0.29682875 0.29682875]\n",
      "  warnings.warn(\n",
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.6061039  0.59818182 0.59818182 0.55595455 0.33905844 0.64838961\n",
      " 0.33905844 0.59818182 0.33905844 0.49646753 0.33905844 0.33905844\n",
      " 0.59818182 0.         0.64838961 0.33905844 0.59818182 0.63924675\n",
      " 0.58675325 0.15542857 0.39246753 0.59818182 0.59818182 0.59818182\n",
      " 0.54566883 0.39246753 0.59818182 0.65861039 0.6061039  0.59818182\n",
      " 0.63924675 0.62438961 0.62438961 0.15314286 0.33905844 0.15542857\n",
      " 0.59818182 0.33905844 0.69517532 0.4851039  0.59818182 0.59818182\n",
      " 0.         0.59818182 0.15542857 0.6061039  0.33905844 0.59818182\n",
      " 0.59818182 0.21942857 0.59818182 0.59818182 0.59818182 0.72825325\n",
      " 0.33905844 0.65181169 0.59818182 0.59818182 0.15542857 0.59818182\n",
      " 0.33905844 0.59818182 0.49766883 0.27391558 0.         0.\n",
      " 0.072      0.59818182 0.59818182 0.39246753 0.59818182 0.61753247\n",
      " 0.59818182 0.33905844 0.6061039  0.         0.59818182 0.63924675\n",
      " 0.59818182 0.33905844 0.59818182 0.53538312 0.59818182 0.6061039\n",
      " 0.59818182 0.58675325 0.         0.27391558 0.59818182 0.55924675\n",
      " 0.33905844 0.59818182 0.59818182 0.63924675 0.15314286 0.6655\n",
      " 0.64951948 0.59818182 0.33905844 0.59818182 0.54566883 0.60953247\n",
      " 0.4931039  0.67003896 0.6061039  0.59818182 0.39246753 0.70318182\n",
      " 0.59818182 0.                nan 0.49766883 0.         0.65522078\n",
      " 0.59818182 0.65181169 0.54681169 0.6061039  0.33905844 0.59818182\n",
      " 0.70318182 0.69175325 0.62438961 0.         0.6632013  0.56624026\n",
      " 0.59818182 0.59818182 0.         0.64381818 0.15542857 0.33905844\n",
      " 0.59818182 0.15542857 0.54566883 0.59818182 0.49538312 0.37783117\n",
      " 0.64838961 0.39246753 0.59818182 0.072      0.33905844 0.59818182\n",
      " 0.         0.         0.39246753 0.33905844 0.58675325 0.59818182\n",
      " 0.59818182 0.4851039  0.49646753 0.65638961 0.59818182 0.64267532\n",
      " 0.59818182 0.59818182 0.15314286 0.15542857 0.         0.33905844\n",
      " 0.53538312 0.62318182 0.27391558 0.59818182 0.65524675 0.\n",
      " 0.59818182 0.49646753 0.33905844 0.59818182 0.62438961 0.59818182\n",
      " 0.4931039  0.15542857 0.73061688 0.59818182 0.46027273 0.33905844\n",
      " 0.59818182 0.33905844 0.39246753 0.71117532 0.         0.59467532\n",
      " 0.6061039  0.54566883 0.59818182 0.59818182 0.59818182 0.59818182\n",
      " 0.59818182 0.55924675 0.072      0.59818182 0.49646753 0.53538312\n",
      " 0.59818182 0.63924675 0.59818182 0.33905844 0.59818182 0.59818182\n",
      " 0.63924675 0.65524675 0.59818182 0.58675325 0.59818182 0.59818182\n",
      " 0.53538312 0.59818182 0.59818182 0.59818182 0.59818182 0.6061039\n",
      " 0.59818182 0.67003896 0.59818182 0.59818182 0.71230519 0.55595455\n",
      " 0.33905844 0.15542857 0.         0.39246753 0.59818182 0.64267532\n",
      " 0.65181169 0.60146753 0.63924675 0.         0.         0.33905844\n",
      " 0.33905844 0.         0.33905844 0.49646753 0.         0.\n",
      " 0.072      0.59818182 0.15542857 0.49646753 0.59818182 0.59818182\n",
      " 0.39246753 0.70318182 0.6061039  0.         0.59818182 0.59818182\n",
      " 0.33905844 0.15314286 0.58675325 0.55595455 0.70318182 0.59467532\n",
      " 0.59818182 0.48281818 0.33905844 0.15542857 0.15542857 0.15314286\n",
      " 0.33905844 0.59818182 0.59818182 0.65181169 0.58675325 0.33905844\n",
      " 0.59818182 0.27391558 0.15542857 0.33905844 0.59818182 0.59818182\n",
      " 0.33905844 0.59818182 0.55595455 0.59818182 0.59818182 0.64838961\n",
      " 0.55595455 0.59818182 0.39246753 0.63924675 0.33905844 0.15542857\n",
      " 0.         0.59818182 0.54681169 0.59818182 0.39246753 0.59818182\n",
      " 0.15314286 0.33905844 0.49538312 0.55595455 0.59818182 0.\n",
      " 0.59818182 0.49766883 0.54681169 0.27391558 0.49646753 0.59818182\n",
      " 0.67467532 0.53538312 0.58324675 0.49424026 0.15542857 0.33905844\n",
      " 0.59818182 0.         0.59818182 0.69175325 0.59818182 0.33905844\n",
      " 0.         0.58324675 0.63924675 0.59818182 0.63924675 0.59818182\n",
      " 0.54567532 0.59818182 0.58324675 0.59818182 0.         0.33905844\n",
      "        nan 0.59818182 0.33905844 0.33905844 0.33905844 0.4931039\n",
      " 0.64724026 0.55595455 0.49538312 0.61866883 0.59818182 0.65638961\n",
      " 0.33905844 0.59818182 0.33905844 0.33905844 0.62438961 0.58324675\n",
      " 0.59818182 0.65178571 0.59818182 0.50338961 0.64838961 0.\n",
      " 0.59818182 0.4931039  0.59818182 0.072      0.63924675 0.65067532\n",
      " 0.         0.59818182 0.65638961 0.59818182 0.59818182 0.15542857\n",
      " 0.39246753 0.59818182 0.         0.63924675 0.59818182 0.59818182\n",
      " 0.15542857 0.59818182 0.54566883 0.072      0.         0.072\n",
      " 0.         0.62438961 0.6061039  0.69292208 0.59818182 0.59818182\n",
      " 0.59818182 0.59818182 0.59818182 0.62438961 0.68146753 0.\n",
      " 0.59818182 0.39246753 0.072      0.27391558 0.33905844 0.59818182\n",
      " 0.65067532 0.59818182 0.39246753 0.6061039  0.33905844 0.33905844\n",
      " 0.         0.59818182 0.15542857 0.63924675 0.15314286 0.62438961\n",
      " 0.59818182 0.59818182 0.59818182 0.51253247 0.6061039  0.70318182\n",
      " 0.59818182 0.59818182 0.59818182 0.66663636 0.15542857 0.59818182\n",
      " 0.59818182 0.         0.         0.59818182 0.49646753 0.65181169\n",
      " 0.49766883 0.59818182 0.6768961  0.33905844 0.59818182 0.39246753\n",
      " 0.59818182 0.59818182 0.59818182 0.59818182 0.6061039  0.33905844\n",
      " 0.49538312 0.39246753 0.59818182 0.59818182 0.63695455 0.\n",
      " 0.59818182 0.59818182 0.59818182 0.33905844 0.59818182 0.59818182\n",
      " 0.33905844 0.69175325 0.6061039  0.15314286 0.59818182 0.59818182\n",
      " 0.64837013 0.59818182 0.59818182 0.50338961 0.59818182 0.15314286\n",
      " 0.58324675 0.59818182 0.59818182 0.59818182 0.59818182 0.15314286\n",
      " 0.15314286 0.33905844 0.59818182 0.27391558 0.59818182 0.33905844\n",
      " 0.62438961 0.62438961 0.59818182 0.33905844 0.59818182        nan\n",
      " 0.59818182 0.70318182 0.33905844 0.33905844 0.6061039  0.61866883\n",
      " 0.50338961 0.66435714 0.59818182 0.49646753 0.59818182 0.39246753\n",
      " 0.59818182 0.         0.58324675 0.15542857 0.59818182 0.55595455\n",
      " 0.33905844 0.33905844]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,25), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7b9d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.7076109936575052\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 76, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "2560 fits failed out of a total of 5120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1280 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 247, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_leaf == -1, must be >= 1.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1280 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 247, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_leaf == 0, must be >= 1.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.70761099 0.70761099 0.70761099]\n",
      "  warnings.warn(\n",
      "C:\\Users\\arihe\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.70545455 0.70545455 0.70545455]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e06781f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9760000 Precision=0.9122807 Recall=0.6265060 F1=0.7428571\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "889a28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57761666",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee59d480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.978000   1.000000  0.602410   \n",
       "0                     default logistic  0.978000   1.000000  0.602410   \n",
       "0                   liblinear logistic  0.978000   1.000000  0.602410   \n",
       "0                          L2 logistic  0.978000   1.000000  0.602410   \n",
       "0                          L1 logistic  0.978000   1.000000  0.602410   \n",
       "0                     Elestic logistic  0.978000   1.000000  0.602410   \n",
       "0                           linear svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "0                             poly svm  0.970000   0.806452  0.602410   \n",
       "0                        Decision Tree  0.976000   0.912281  0.626506   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "\n",
       "         F1  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.751880  \n",
       "0  0.724638  \n",
       "0  0.689655  \n",
       "0  0.742857  \n",
       "0  0.617143  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e8fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25372b1a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb8e84",
   "metadata": {},
   "source": [
    "Summarizing the recall score for different models\n",
    "\n",
    "> Logistic Regression\n",
    "\n",
    "    Logistic Regression using Random & Grid search - 0.60241\n",
    "    default logistic Regression\t                   - 0.60241\t\n",
    "\tliblinear logistic Regression     \t           - 0.60241\n",
    "    L2 logistic\tRegression                         - 0.60241\n",
    "\tL1 logistic\tRegression                         - 0.60241\n",
    "\tElestic logistic Rgression                     - 0.60241\n",
    "    \n",
    "   **Here we can observe that all logistic Regression models are having the same Recall score**\n",
    "    \n",
    "> Support Vector Machine \n",
    "    \n",
    "    SVM using Random & Grid search - 0.65060\n",
    "    Linear SVM\t                   - 0.60241\t\n",
    "\tRBF SVM     \t               - 0.60241\n",
    "    Poly SVM                       - 0.60241\n",
    "    \n",
    "   **The SVM using the Grid search and the Random Search has the highest recall score**\n",
    "> Decision Tree\n",
    "    \n",
    "    Using Random & Grid search - 0.626506\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8a21d",
   "metadata": {},
   "source": [
    "From the results we can observe that the recall score in each type of model is greater if we use the Random Search and Grid Search approch. And the recall score is same for the all logistic regression model and the Support Vector Machines model except the SVM with RandomSearch and GridSearch. This could be due to the imbalance in the data. In the begining we have observed that there is very huge imbalace in the target variable data and due to that all the models are producing almost same recall score.\n",
    "\n",
    "But if consider the differneces in the scores,  SVM model has the highest recall score i.e. 0.65060 which is not so high when compared to the other two models but is the best of all three models. So the best model from all the models we have trained and tested is **Support Vector Machine**. And the parameters at which the highest recall score acheived is \n",
    "\n",
    "- C(regulization parameter): 37.1\n",
    "- coef0(for ploynomial in ploy kernal SVM): 7 \n",
    "- degree(Degree of the ploynomial in polySVM): 4\n",
    "- gamma= 'scale'\n",
    "- kernel: 'poly'.\n",
    "\n",
    "Universal bank can use the Support Vector Machines with poly kernal to find the potential coustmers to sell their new CD account product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ea73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
